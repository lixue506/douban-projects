# -*- coding: utf-8 -*-
import requests
import json
import urllib.request
import urllib.parse
import string
from bs4 import BeautifulSoup

url_list = []# 存储自链接

#怕段标签
def judge_url(url):
    if url in url_list:
        return 0
    else:
        url_list.append(url)
        return 1

#控制翻页，标签
def make_url(a,lis):
    url1 = 'https://movie.douban.com/j/search_subjects?type=movie&tag='
    url2 = '&sort=recommend&page_limit=20&page_start=' + str(a)
    add_url = url1 + lis + url2
    url = urllib.parse.quote(add_url, safe=string.printable)
    return url

#返回主界面json数据
def get_html(url):
    try:
        d = {
            'User Agent': "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 SE 2.X MetaSr 1.0"}
        r = requests.get(url=url, headers=d)
        if r.status_code == 200:
            print(json.loads(r.text)['subjects'][0])
            return json.loads(r.text)
    except:
        print( "爬取失败" )
        return None

#分析返回子页面
def get_son_html(url):
    try:
        d = {
            'User Agent': "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 SE 2.X MetaSr 1.0"}
        r = requests.get(url=url, headers=d)
        if r.status_code == 200:
            return r.text
    except:
        print( "爬取失败" )
        return None

#定位爬取
def params_son_html(son_html):
    soup = BeautifulSoup(son_html)
    # tag
    tags = soup.find_all( 'span', attrs={'property': "v:genre"} )
    # 评分人数
    people = soup.find('span', attrs={'property': "v:votes"})
    # 五星评分
    star = soup.find_all('span', attrs={'class': "rating_per"})
    # 写入文件
    with open("电影.txt", 'a', encoding='utf-8') as f:
        f.write(people.text + ',')
        for num in star:#评分1-5
            f.write(num.text + ",")
        for tag in tags:#类型
            f.write(str(tag.text) + ",")
        f.write("\n")
    f.close()

#分析电影显示页，并获取电影名称，评分
def params_html(json_dict):
    for i in json_dict['subjects']:
        print(i['url'])
        href = i['url']
        if judge_url(href) == 1:#判断电影是否已爬取，去重
            with open( "movie.txt", 'a', encoding='utf-8' ) as f:
                f.write(i['title']+';'+i['rate']+';')
            f.close()
            #解析子页面
            son_html = get_son_html(href)
            #定位爬取子页面内容
            params_son_html(son_html)
            print(href)

#根据电影标签爬取所有电影
def main():
    lis_name = ["热门", "最新","经典","可播放","豆瓣高分","冷门佳片","华语","欧美","韩国",\
                "日本","动作","喜剧","爱情","科幻","悬疑","恐怖","成长"]
    for lis in lis_name:
        print("正在爬取标签" + lis)
        a = 0
        while True:
            url = make_url(a, lis)
            html = get_html(url)
            a += 20
            if len(html['subjects']) == 20:
                params_html( html )
            else:
                params_html( html )
                print( "爬取完成单项" )
                break
    print("爬取完成")

main()